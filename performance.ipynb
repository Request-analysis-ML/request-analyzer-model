{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from notebooks.train_test_divide import extract_spammers_scrapers, extract_normal, split_train_test, label_data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "dir = path.replace('notebooks', 'api_files')\n",
    "os.chdir(dir)\n",
    "from api_files.ml_library import read_csv_file, clean_reqlogs, extract_users, split_user_df, calc_avg_timediff, avg_tokens_5mins, longest_consec, get_variance_score, sequence_time_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = []\n",
    "true_neg = []\n",
    "false_pos = []\n",
    "false_neg = []\n",
    "\n",
    "for i in range(100):\n",
    "    #Creating train data\n",
    "    path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    dir = path.replace('notebooks', 'csv_files')\n",
    "    os.chdir(dir)\n",
    "    \n",
    "    #Train\n",
    "    data_calc = pd.read_csv('csv_files/calculations80.csv')\n",
    "    df_spam = extract_spammers_scrapers(data_calc)\n",
    "    split_train_test(extract_normal(data_calc, df_spam), df_spam)\n",
    "    df_anomaly_train = pd.read_csv('csv_files/train.csv')\n",
    "\n",
    "    #Fit model\n",
    "    anomaly_inputs = ['request_freq', 'avg_tokens', 'longest_consec', 'var_score', 'sequence_time']\n",
    "    #anomaly_inputs = ['var_score', 'longest_consec']\n",
    "    model_if = IsolationForest(contamination=0.002, random_state=42)\n",
    "    model_if.fit(df_anomaly_train[anomaly_inputs].values)   \n",
    "\n",
    "    #Create test data\n",
    "    data_calc = pd.read_csv('csv_files/calculations80.csv')\n",
    "    df_spam = extract_spammers_scrapers(data_calc)\n",
    "    split_train_test(extract_normal(data_calc, df_spam), df_spam)   \n",
    "    df_anomaly_test = pd.read_csv('csv_files/test.csv')\n",
    "\n",
    "\n",
    "    #Code for checking how many spammers and scarpers that are present in test dataset\n",
    "    spam = extract_spammers_scrapers(df_anomaly_test)\n",
    "    normal = extract_normal(df_anomaly_test, spam)\n",
    "    spam_true = spam.shape[0]\n",
    "    normal_true = normal.shape[0]\n",
    "\n",
    "\n",
    "    #Predict test data\n",
    "    df_anomaly_test['anomaly_score'] = model_if.decision_function(df_anomaly_test[anomaly_inputs].values)\n",
    "    df_anomaly_test['anomaly'] = model_if.predict(df_anomaly_test[anomaly_inputs].values)\n",
    "    df_anomaly_score = df_anomaly_test.loc[:,['anomaly_score', 'anomaly']]\n",
    "    df_anomaly_score['user'] = df_anomaly_test['user']\n",
    "    df_a = df_anomaly_score.loc[df_anomaly_score['anomaly_score'] < 0] \n",
    "\n",
    "\n",
    "    spam = extract_spammers_scrapers(df_a)\n",
    "    tp = spam.shape[0]\n",
    "    fp = extract_normal(df_a, spam).shape[0]\n",
    "    tn = normal_true - fp\n",
    "    fn = spam_true - tp\n",
    "\n",
    "    true_pos.append(tp)\n",
    "    true_neg.append(tn)\n",
    "    false_pos.append(fp)\n",
    "    false_neg.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1674,    0],\n",
       "       [   0,  424]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Values taken from average\n",
    "cf_matrix = np.array([[math.floor(np.average(true_pos)), math.floor(np.average(false_neg))],[math.floor(np.average(false_pos)), math.floor(np.average(true_neg))]])\n",
    "cf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
