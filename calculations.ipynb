{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_functions import read_csv_file, extract_users, split_user_df, clean_reqlogs\n",
    "from calculations import longest_consec, calc_avg_timediff, get_variance_score\n",
    "from sessionID_check import avg_tokens_5mins\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code for fetching the data\"\"\"\n",
    "\n",
    "#Fetch data from csv file\n",
    "data = read_csv_file('requests.csv')\n",
    "\n",
    "#Extracts a list of all unique users in dataframe\n",
    "users = extract_users(data)\n",
    "\n",
    "#Fetches the first user in list\n",
    "user1 = users[1]\n",
    "\n",
    "data_chunk = split_user_df(data, user1)[0]\n",
    "\n",
    "#longest_consec(data_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'todense'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m vectorizer \u001b[39m=\u001b[39m CountVectorizer()\n\u001b[0;32m      4\u001b[0m x \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit(cleaned[\u001b[39m'\u001b[39m\u001b[39mrequest_logs\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m df_vectorized \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(x\u001b[39m.\u001b[39;49mtodense(), columns\u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mget_feature_names_out())\n\u001b[0;32m      7\u001b[0m df_vectorized\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'todense'"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "cleaned = clean_reqlogs(df)\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit(cleaned['request_logs'])\n",
    "\n",
    "df_vectorized = pd.DataFrame(x.todense(), columns= vectorizer.get_feature_names_out())\n",
    "df_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "block          NaN\n",
       "chat           NaN\n",
       "config         NaN\n",
       "conversation   NaN\n",
       "inbox          NaN\n",
       "like           NaN\n",
       "login          NaN\n",
       "markasread     NaN\n",
       "page           NaN\n",
       "photos         NaN\n",
       "profile        NaN\n",
       "report         NaN\n",
       "searchusers    NaN\n",
       "send           NaN\n",
       "userconfig     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_variance_score(dataframe, vectorizer):\n",
    "    df = dataframe.copy()\n",
    "    cleaned = clean_reqlogs(df)\n",
    "\n",
    "    x = vectorizer.transform(cleaned['request_logs'])\n",
    "\n",
    "    df_vectorized = pd.DataFrame(x.todense(), columns= vectorizer.get_feature_names_out() )\n",
    "    #return df_vectorized.sort_values(by=[\"vect_scores\"], ascending=False)\n",
    "    #list = df_vectorized.sort_values(by=[\"vect_scores\"], ascending=False)\n",
    "    return df_vectorized.var()\n",
    "\n",
    "get_variance_score(data_chunk, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame()\n",
    "for user in users:\n",
    "    data_chunks = split_user_df(data, user)\n",
    "    avg_req_frequences = []\n",
    "    avg_tokens = []\n",
    "    repetitions = []\n",
    "\n",
    "    for i in range(0, len(data_chunks)):\n",
    "        avg_req_frequences.append(calc_avg_timediff(data_chunks[i]))\n",
    "        avg_tokens.append(avg_tokens_5mins(data_chunks[i]))\n",
    "        repetitions.append(longest_consec(data_chunks[i]))\n",
    "    \n",
    "    user_df = pd.DataFrame()\n",
    "    user_df['request_freq'] = avg_req_frequences\n",
    "    user_df['avg_tokens'] = avg_tokens\n",
    "    user_df['longest_consec'] = repetitions\n",
    "    user_df['user'] = user\n",
    "    df_calculations = pd.concat([df_calculations, user_df])\n",
    "\n",
    "df_calculations.reset_index(inplace=True)\n",
    "df_calculations = df_calculations.drop(columns='index')\n",
    "df_calculations.to_csv('calculations.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for creating csv-file containing information about average request frequency, average number of tokens per 5 mins, \n",
    "longest consecutive chain of repetitive requests for every chunk of 50 requests for each user\n",
    "\"\"\"\n",
    "\n",
    "df_calculations = pd.DataFrame()\n",
    "for user in users:\n",
    "    data_chunks = split_user_df(data, user)\n",
    "    avg_req_frequences = []\n",
    "    avg_tokens = []\n",
    "    repetitions = []\n",
    "\n",
    "    for i in range(0, len(data_chunks)):\n",
    "        avg_req_frequences.append(calc_avg_timediff(data_chunks[i]))\n",
    "        avg_tokens.append(avg_tokens_5mins(data_chunks[i]))\n",
    "        repetitions.append(longest_consec(data_chunks[i]))\n",
    "    \n",
    "    user_df = pd.DataFrame()\n",
    "    user_df['request_freq'] = avg_req_frequences\n",
    "    user_df['avg_tokens'] = avg_tokens\n",
    "    user_df['longest_consec'] = repetitions\n",
    "    user_df['user'] = user\n",
    "    df_calculations = pd.concat([df_calculations, user_df])\n",
    "\n",
    "df_calculations.reset_index(inplace=True)\n",
    "df_calculations = df_calculations.drop(columns='index')\n",
    "df_calculations.to_csv('calculations.csv', index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
